## 清楚記載這個專案的目的和結果，最後的推薦分數是多少，是否有成功
本次專案目的為測試及比較3種不同的collaborative filtering方法，去找出對於整體預測分數較高的推薦方式。在剛開始研究這3種方法時我發現了它們各自有自己適合的應用場景，對於不同類型的資料型態都有自己適合使用的方法。
經過比較及測試後，我得到3種推薦方法的預測分數在User_based / Item_based / Surprise套件分別是0 / 0.33% / 0，我個人認為雖然這三個推薦方法最終的預測分數都不是很高，但是我還是有找出在本次資料集中最適合的推薦方法。

## 簡明清楚的使用說明：用了哪三種方法實作？為什麼？
本次使用的3種推薦方法分別是User_based / Item_based / Surprise 的collaborative filtering 推薦法。因為本次使用的資料集是電商資料，透過EDA的執行有發現到訓練資料中的用戶有32萬明顯大於商品數的3萬，也因此我有考量到如果透過User_based跑資料將會面臨到運算過多而記憶體耗盡的問題。

首先在執行User_based前我有先把訓練資料中 “購買數少於3次的用戶作剔除”，最終也才能順利跑出推薦結果，然而User_based的推薦分數是0，我認為最大的問題還是出在因為先前設定一個比較嚴格的門檻 : 用戶的購買數要大於3 (90%的用戶都只有買過1個產品)，因此將導致在推薦時能夠找到相似的用戶數也會大幅下滑。

第二個執行的是Item_based的推薦法，相較於透過User_based需要注意的運算問題，這邊的資料因為商品數較用戶數少很多，所以透過Item_based執行時就比較沒有運算上的問題，而為了優化最終的推薦結果，我有先將訓練資料中先做ETL處理，將 “同個用戶重複購買同個商品的評分分數取平均值”，這樣不但能去除重複的資料，也能對後續計算相似度分數時有更好的代表性。很幸運的，最終我透過上述方法以Item_based跑出癌的預測分數就有高於sample code的推薦分數。

第三個執行的是Surprise套件，和前面兩種透過手刻實作出來的推薦法不同的是，Surprise套件有滿多Collaborative filtering的演算法，我們不用額外計算相似度矩陣。而這次我採用的是KNN結合Item_based的算法，我有發現到最終跑出來的分數是0，主要原因是我為了要在colab可以跑所以將訓練資料只抓在2017/9/1-2018/9/1，導致最終沒有夠多的相似用戶可以作推薦，未來我也會多加嘗試套件中其他不同的演算法並比較它們之間的預測準確性。

